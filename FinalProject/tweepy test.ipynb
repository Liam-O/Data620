{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up access credentials\n",
    "consumer_info = [line.strip() for line in open(\"df_twitter_consumer_auth.txt\")]\n",
    "access_info = [line.strip() for line in open(\"df_twitter_access_auth.txt\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#authorize twitter, initialize tweepy\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth)\n",
    "new_tweets = api.user_timeline(screen_name = \"CremeDeLaCrypto\",count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "search_terms = [\"bitcoin\",\"blockchain\",\"crypto\",\"cryptocurrency\",\"btc\",\"ethereum\"]\n",
    "\n",
    "for item in t:\n",
    "    if any(term in item.text.lower() for term in search_terms):\n",
    "        print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'excited about crypto?!\\n\\ninvesting *financial capital* is just one way to go long the industry. \\n\\nanother is to inveâ€¦ https://t.co/ksrnysdt5j'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[9].text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "\n",
    "#save most recent tweets\n",
    "b = [item for item in new_tweets if any(term in item.text.lower() for term in search_terms)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original source: https://gist.github.com/yanofsky/5436496\n",
    "\n",
    "import tweepy #https://github.com/tweepy/tweepy\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "#Twitter API credentials\n",
    "consumer_key = consumer_info[0]\n",
    "consumer_secret = consumer_info[1]\n",
    "access_key = access_info[0] \n",
    "access_secret = access_info[1]\n",
    "\n",
    "\n",
    "def get_all_tweets(screen_name,datetime_limit, search_terms):\n",
    "    #Twitter only allows access to a users most recent 3240 tweets with this method\n",
    "    \n",
    "    #authorize twitter, initialize tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "    #initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = []    \n",
    "    \n",
    "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    new_tweets = api.user_timeline(screen_name = screen_name,count=200)\n",
    "    \n",
    "    #Filter and save most recent tweets\n",
    "    filtered_tweets = [item for item in new_tweets if any(term in item.text.lower() for term in search_terms)]\n",
    "    alltweets.extend(filtered_tweets)\n",
    "    \n",
    "    #save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "    \n",
    "    #keep grabbing tweets until there are no tweets left to grab\n",
    "    while (len(new_tweets) > 0):\n",
    "            \n",
    "        new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)\n",
    "\n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "\n",
    "        #update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "\n",
    "        print (screen_name + \" \" +str(alltweets[-1].created_at))\n",
    "\n",
    "        if (alltweets[-1].created_at <= datetime_limit):\n",
    "            print (\"Reached the limit \" + str(datetime_limit))\n",
    "            print (screen_name + \" : %s tweets downloaded\" % (len(alltweets)))\n",
    "            break\n",
    "            \n",
    "          \n",
    "    #transform the tweepy tweets into a 2D array that will populate the csv    \n",
    "    outtweets = [[tweet.id_str, tweet.created_at, tweet.text.encode(\"utf-8\")] for tweet in alltweets]\n",
    "    \n",
    "    return outtweets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tweets = get_all_tweets(\"Cointelegraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINTECHcircle 2017-11-06 16:48:10\n",
      "FINTECHcircle 2017-10-25 03:45:01\n",
      "FINTECHcircle 2017-10-04 07:02:31\n",
      "FINTECHcircle 2017-09-15 11:37:04\n",
      "FINTECHcircle 2017-08-17 09:41:43\n",
      "FINTECHcircle 2017-07-18 11:45:10\n",
      "FINTECHcircle 2017-06-28 12:15:59\n",
      "FINTECHcircle 2017-06-24 16:07:21\n",
      "FINTECHcircle 2017-06-06 08:40:01\n",
      "FINTECHcircle 2017-05-15 15:55:47\n",
      "FINTECHcircle 2017-04-25 16:25:21\n",
      "FINTECHcircle 2017-04-04 12:19:04\n",
      "FINTECHcircle 2017-03-13 12:43:14\n",
      "FINTECHcircle 2017-02-23 11:39:23\n",
      "FINTECHcircle 2017-02-01 07:04:05\n",
      "FINTECHcircle 2017-01-31 08:11:55\n",
      "FINTECHcircle 2017-01-31 08:11:55\n",
      "cburniske 2017-11-19 19:00:00\n",
      "cburniske 2017-11-06 14:17:44\n",
      "cburniske 2017-10-21 16:22:19\n",
      "cburniske 2017-10-05 20:15:57\n",
      "cburniske 2017-09-21 11:09:05\n",
      "cburniske 2017-09-05 21:22:39\n",
      "cburniske 2017-08-25 22:23:54\n",
      "cburniske 2017-08-14 02:47:47\n",
      "cburniske 2017-08-02 20:05:44\n",
      "cburniske 2017-07-20 17:52:22\n",
      "cburniske 2017-07-10 11:49:08\n",
      "cburniske 2017-07-02 17:43:23\n",
      "cburniske 2017-06-21 19:16:07\n",
      "cburniske 2017-06-14 12:46:24\n",
      "cburniske 2017-06-05 14:31:20\n",
      "cburniske 2017-06-04 18:09:33\n",
      "cburniske 2017-06-04 18:09:33\n",
      "niccary 2016-08-17 00:00:44\n",
      "Reached the limit 2017-01-01 00:00:00\n",
      "niccary : 304 tweets downloaded\n",
      "CremeDeLaCrypto 2017-09-24 17:39:59\n",
      "CremeDeLaCrypto 2017-07-11 14:31:43\n",
      "CremeDeLaCrypto 2017-04-11 17:48:46\n",
      "CremeDeLaCrypto 2017-03-02 17:17:07\n",
      "CremeDeLaCrypto 2017-02-21 20:01:57\n",
      "CremeDeLaCrypto 2017-02-21 20:01:57\n",
      "Cointelegraph 2017-12-03 13:12:00\n",
      "Cointelegraph 2017-11-24 12:21:05\n",
      "Cointelegraph 2017-11-17 09:47:42\n",
      "Cointelegraph 2017-11-09 13:50:46\n",
      "Cointelegraph 2017-11-02 08:05:36\n",
      "Cointelegraph 2017-10-26 12:35:24\n",
      "Cointelegraph 2017-10-18 21:21:12\n",
      "Cointelegraph 2017-10-11 14:45:44\n",
      "Cointelegraph 2017-10-04 13:18:20\n",
      "Cointelegraph 2017-09-27 11:07:45\n",
      "Cointelegraph 2017-09-17 12:07:35\n",
      "Cointelegraph 2017-09-08 07:08:16\n",
      "Cointelegraph 2017-08-30 22:59:23\n",
      "Cointelegraph 2017-08-21 09:37:39\n",
      "Cointelegraph 2017-08-11 13:55:13\n",
      "Cointelegraph 2017-08-09 12:27:48\n",
      "Cointelegraph 2017-08-09 12:27:48\n",
      "aantonop 2017-11-13 12:48:22\n",
      "aantonop 2017-10-21 13:45:06\n",
      "aantonop 2017-09-21 02:53:12\n",
      "aantonop 2017-09-08 12:41:53\n",
      "aantonop 2017-08-15 19:49:17\n",
      "aantonop 2017-07-26 19:45:12\n",
      "aantonop 2017-06-27 08:59:10\n",
      "aantonop 2017-05-27 13:50:11\n",
      "aantonop 2017-04-27 11:10:06\n",
      "aantonop 2017-03-13 11:33:51\n",
      "aantonop 2017-02-02 07:54:23\n",
      "aantonop 2017-01-04 13:15:11\n",
      "aantonop 2016-11-27 16:08:10\n",
      "Reached the limit 2017-01-01 00:00:00\n",
      "aantonop : 2642 tweets downloaded\n"
     ]
    }
   ],
   "source": [
    "# Source: https://www.reddit.com/r/Bitcoin/comments/6m6g0c/who_are_some_good_people_to_follow_on_twitter_for/\n",
    "\n",
    "twitter_accounts = [\"FINTECHcircle\",\"cburniske\",\"niccary\",\"CremeDeLaCrypto\",\"Cointelegraph\",\"aantonop\"]\n",
    "search_terms = [\"bitcoin\",\"blockchain\",\"crypto\",\"cryptocurrency\",\"btc\",\"ethereum\",\"litecoin\",\"bch\",\"eth\"]\n",
    "datetime_limit = datetime.datetime(2017, 1, 1, 0, 0, 0)\n",
    "\n",
    "tweets = []\n",
    "for account in twitter_accounts:\n",
    "    tmp = get_all_tweets(account,datetime_limit,search_terms)\n",
    "    tweets.extend(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13345"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tw_export = pd.DataFrame({\n",
    "    \"tweet\":[item[2].decode(\"utf-8\") for item in tweets],\n",
    "    \"timestamp\":[item[1].strftime(\"%Y-%m-%d %H:%M:%S\") for item in tweets]\n",
    "})\n",
    "tw_export.head()\n",
    "\n",
    "tw_export[[\"tweet\",\"timestamp\"]].to_csv(\"data/tweepy_tweets.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
